
[Task]
# the root path of the project: subfolders (source_data, trained_models) will be created automatically.
project_path = './data'
# task_name, unique identifier for each task in the projects
task_name = 'Flare_downseg_20'
# task_type: segmentatin, or others
task_type = 'segmentatin'
# target of segmentation
seg_targets = [
        'liver',
        'right_kidney', 
        'spleen', 
        'pancreas', 
        'aorta', 
        'inferior_venacava', 
        'right_adrenal_gland', 
        'left_adrenal_gland', 
        'gallbladder', 
        'esophagus', 
        'stomach', 
        'duodenum', 
        'left_kidney', 
        ]


[Train]
# max epochs
max_epochs = 1000
# save every epochs
save_every_epochs = 50
# test with validation set every ? epoches. A negative number means no interval
val_interval = -1
# continue training
continue_training = false
# GPU id
device = 'cuda:0'
# name of model
model = 'model_sam_downstream_seg'
# name of trainer
trainer = 'trainer_SAM_downstream_seg'
# name of loss
loss = 'DiceCELoss'
# name of data loader class
data_loader = 'dataloader_seg_preprocessed'
# val amp
val_amp = true
# fixed random seed
reproducibility = true
# roi size
roi_size = [160, 160, 160]

[Train.model_sam_downstream_seg]
network_name = 'sam_downstream_unet_3d'
# size of the global feature and the local feature of the network output
in_sam_channels = 64
# num of res units in each layer
num_res_units = 1
# disable sam
disable_sam = false
# disable global
disable_global = true

[Train.trainer_SAM_downstream_seg]
sam_target_feature_size = 64
sam_num_res_units = 2
sam_model_name = './data/trained_models/abdomen_foundation.pth'
# input_dropout
input_dropout = false
# network_name
network_name = 'sam_with_unet'

[Train.dataloader_seg_preprocessed]
# split method for training, validation and testing dataset
split_method = 'file_assignment'
# path of split file
split_filename = '/home/mingrui/disk1/projects/monai/Projects/202302_FedSAM/config_files/split_sam_flare_1mm_fullseg.json'
# group name or name list
train_group = ['train',]
val_group = ['val',]
partial_dataset = 20
# preprocessed
preprocessed = true
# batch size
batch_size = 2
# percentage of cached data in total
cache_rate = 1.0
# the number of worker threads to use
num_workers = 16
# pix dim
pixdim = [1.0, 1.0, 1.0]
# rand flip
rand_flip = false
# rand zoom
rand_zoom = true
# rand rotate
rand_rotate = true
# rand scale intensity
rand_scale_intensity = true
# rand shift intensity
rand_shift_intensity = true
# debug model
debug_model = false
# debug_model = true

[Inference]
# folder name of this inference
inference_name = 'downstream'
# save inference labels to dict or not
save_label_file = true
# name of inference class
inference = 'inference_sam_downstream_seg'
# data to inference
data_loader = 'dataloader_wo_label'
# model name
model_name = 'downstream_seg.pth'
# GPU id
device = 'cuda:0'
# sliding window device
sliding_window_device = 'None' # gpu
# sliding_window_device = 'cpu' # cpu
# val amp
val_amp = true

[Inference.dataloader_wo_label]

# split method for training, validation and testing dataset
split_method = 'file_assignment'
# path of split file
split_filename = './config_files/split_test.json'
# group name or name list in split file, when model is 'split_file'.
test_group = ['test',]
# preprocessed
preprocessed = false
# pix dim
pixdim = [1.0, 1.0, 1.0]
# percentage of cached data in total
cache_rate = 0.0
# the number of worker threads to use
num_workers = 1

# batch size
batch_size = 1
# debug model
debug_model = false